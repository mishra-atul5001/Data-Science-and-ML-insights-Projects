{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "A Convolutional Neural Network (CNN) for image classification is made up of multiple layers that extract features, such as edges, corners, etc; and then use a final fully-connected layer to classify objects based on these features. You can visualize this like this:\n",
    "\n",
    "<table>\n",
    "    <tr><td rowspan=2 style='border: 1px solid black;'>&#x21d2;</td><td style='border: 1px solid black;'>Convolutional Layer</td><td style='border: 1px solid black;'>Pooling Layer</td><td style='border: 1px solid black;'>Convolutional Layer</td><td style='border: 1px solid black;'>Pooling Layer</td><td style='border: 1px solid black;'>Fully Connected Layer</td><td rowspan=2 style='border: 1px solid black;'>&#x21d2;</td></tr>\n",
    "    <tr><td colspan=4 style='border: 1px solid black; text-align:center;'>Feature Extraction</td><td style='border: 1px solid black; text-align:center;'>Classification</td></tr>\n",
    "</table>\n",
    "\n",
    "*Transfer Learning* is a technique where you can take an existing trained model and re-use its feature extraction layers, replacing its final classification layer with a fully-connected layer trained on your own custom images. With this technique, your model benefits from the feature extraction training that was performed on the base model (which may have been based on a larger training dataset than you have access to) to build a classification model for your own specific set of object classes.\n",
    "\n",
    "How does this help? Well, think of it this way. Suppose you take a professional tennis player and a complete beginner, and try to teach them both how to play raquetball. It's reasonable to assume that the professional tennis player will be easier to train, because many of the underlying skills involved in raquetball are already learned. Similarly, a pre-trained CNN model may be easier to train to classify specific set of objects because it's already learned how to identify the features of common objects, such as edges and corners. Fundamentally, a pre-trained model can be a great way to produce an effective classifier even when you have limited data with which to train it.\n",
    "\n",
    "In this notebook, we'll see how to implement transfer learning for a classification model using TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import TensorFlow libraries\n",
    "\n",
    "Let's start my ensuring that we have the latest version of the **TensorFlow** package installed and importing the Tensorflow libraries we're going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.3.1-cp36-cp36m-win_amd64.whl (342.5 MB)\n",
      "Collecting tensorboard<3,>=2.3.0\n",
      "  Using cached tensorboard-2.3.0-py3-none-any.whl (6.8 MB)\n",
      "Collecting keras-preprocessing<1.2,>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.27.2)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in c:\\users\\mishr\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow) (1.12.1)\n",
      "Collecting gast==0.3.3\n",
      "  Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in c:\\users\\mishr\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
      "  Using cached tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
      "Requirement already satisfied, skipping upgrade: numpy<1.19.0,>=1.16.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.18.2)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Collecting h5py<2.11.0,>=2.10.0\n",
      "  Using cached h5py-2.10.0-cp36-cp36m-win_amd64.whl (2.4 MB)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in c:\\users\\mishr\\appdata\\roaming\\python\\python36\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (46.1.3)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.6.11)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2018.4.16)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.22)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.6)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
      "Installing collected packages: tensorboard-plugin-wit, tensorboard, keras-preprocessing, gast, tensorflow-estimator, h5py, tensorflow\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.1.1\n",
      "    Uninstalling tensorboard-2.1.1:\n",
      "      Successfully uninstalled tensorboard-2.1.1\n",
      "  Rolling back uninstall of tensorboard\n",
      "  Moving to c:\\users\\mishr\\appdata\\roaming\\python\\python36\\scripts\\tensorboard.exe\n",
      "   from C:\\Users\\mishr\\AppData\\Local\\Temp\\pip-uninstall-3zr2a68c\\tensorboard.exe\n",
      "  Moving to c:\\users\\mishr\\appdata\\roaming\\python\\python36\\site-packages\\tensorboard-2.1.1.dist-info\\\n",
      "   from c:\\users\\mishr\\appdata\\roaming\\python\\python36\\site-packages\\~ensorboard-2.1.1.dist-info\n",
      "  Moving to c:\\users\\mishr\\appdata\\roaming\\python\\python36\\site-packages\\tensorboard\\\n",
      "   from c:\\users\\mishr\\appdata\\roaming\\python\\python36\\site-packages\\~ensorboard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: rasa 1.10.1 has requirement prompt-toolkit<3.0,>=2.0, but you'll have prompt-toolkit 1.0.18 which is incompatible.\n",
      "ERROR: rasa 1.10.1 has requirement ruamel.yaml<0.17,>=0.16, but you'll have ruamel-yaml 0.15.35 which is incompatible.\n",
      "ERROR: rasa 1.10.1 has requirement tensorflow<2.2,>=2.1, but you'll have tensorflow 2.3.1 which is incompatible.\n",
      "ERROR: rasa 1.10.1 has requirement tensorflow-estimator==2.1.0, but you'll have tensorflow-estimator 2.3.0 which is incompatible.\n",
      "ERROR: rasa-x 0.28.3 has requirement ruamel.yaml<0.17,>=0.16, but you'll have ruamel-yaml 0.15.35 which is incompatible.\n",
      "ERROR: rasa-x 0.28.3 has requirement tensorflow-estimator<2.2.0,>=2.1.0, but you'll have tensorflow-estimator 2.3.0 which is incompatible.\n",
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'c:\\\\programdata\\\\anaconda3\\\\Lib\\\\site-packages\\\\tensorboard\\\\data_compat.py'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: You are using pip version 20.1.1; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the 'c:\\programdata\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.1.0\n",
      "Keras version: 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from  tensorflow import keras\n",
    "print('TensorFlow version:',tensorflow.__version__)\n",
    "print('Keras version:',keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the base model\n",
    "\n",
    "To use transfer learning, we need a base model from which we can use the trained feature extraction layers. The ***resnet*** model is an CNN-based image classifier that has been pre-trained using a huge dataset of 3-color channel images of 224x224 pixels. Let's create an instance of it with some pretrained weights, excluding its final (top) prediction layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 149s 2us/step\n",
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "base_model = keras.applications.resnet.ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "print(base_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the image data\n",
    "\n",
    "The pretrained model has many layers, starting with a convolutional layer that starts the feature extraction process from image data.\n",
    "\n",
    "For feature extraction to work with our own images, we  need to ensure that the image data we use the train our prediction layer has the same number of features (pixel values) as the images originally used to train the feature extraction layers, so we need data loaders for color images that are 224x224 pixels in size.\n",
    "\n",
    "Tensorflow includes functions for loading and transforming data. We'll use these to create a generator for training data, and a second generator for test data (which we'll use to validate the trained model). The loaders will transform the image data to match the format used to train the original resnet CNN model and normalize them.\n",
    "\n",
    "Run the following cell to define the data generators and list the classes for our images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Data...\n",
      "Preparing training dataset...\n",
      "Found 840 images belonging to 3 classes.\n",
      "Preparing validation dataset...\n",
      "Found 360 images belonging to 3 classes.\n",
      "class names:  ['circle', 'square', 'triangle']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_folder = 'data/shapes'\n",
    "pretrained_size = (224,224)\n",
    "batch_size = 30\n",
    "\n",
    "print(\"Getting Data...\")\n",
    "datagen = ImageDataGenerator(rescale=1./255, # normalize pixel values\n",
    "                             validation_split=0.3) # hold back 30% of the images for validation\n",
    "\n",
    "print(\"Preparing training dataset...\")\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_folder,\n",
    "    target_size=pretrained_size, # resize to match model expected input\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training') # set as training data\n",
    "\n",
    "print(\"Preparing validation dataset...\")\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_folder,\n",
    "    target_size=pretrained_size, # resize to match model expected input\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation') # set as validation data\n",
    "\n",
    "classnames = list(train_generator.class_indices.keys())\n",
    "print(\"class names: \", classnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a prediction layer\n",
    "\n",
    "We downloaded the complete *resnet* model excluding its final prediction layer, so need to combine these layers with a fully-connected (*dense*) layer that takes the flattened outputs from the feature extraction layers and generates a prediction for each of our image classes.\n",
    "\n",
    "We also need to freeze the feature extraction layers to retain the trained weights. Then when we train the model using our images, only the final prediction layer will learn new weight and bias values - the pre-trained weights already learned for feature extraction will remain the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 100352)       0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 3)            301059      flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,888,771\n",
      "Trainable params: 301,059\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "\n",
    "# Freeze the already-trained layers in the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create prediction layer for classification of our images\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "prediction_layer = Dense(len(classnames), activation='softmax')(x) \n",
    "model = Model(inputs=base_model.input, outputs=prediction_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Now print the full model, which will include the layers of the base model plus the dense layer we added\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n",
    "With the layers of the CNN defined, we're ready to train it using our image data. The weights used in the feature extraction layers from the base resnet model will not be changed by training, only the final dense layer that maps the features to our shape classes will be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 28 steps, validate for 12 steps\n",
      "Epoch 1/3\n",
      "28/28 [==============================] - 578s 21s/step - loss: 0.3672 - accuracy: 0.9500 - val_loss: 12.5753 - val_accuracy: 0.3333\n",
      "Epoch 2/3\n",
      "28/28 [==============================] - 462s 16s/step - loss: 2.8383e-10 - accuracy: 1.0000 - val_loss: 16.4107 - val_accuracy: 0.3333\n",
      "Epoch 3/3\n",
      "28/28 [==============================] - 459s 16s/step - loss: 3.5904e-08 - accuracy: 1.0000 - val_loss: 16.6666 - val_accuracy: 0.3333\n"
     ]
    }
   ],
   "source": [
    "# Train the model over 3 epochs\n",
    "num_epochs = 3\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // batch_size,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = validation_generator.samples // batch_size,\n",
    "    epochs = num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the loss history\n",
    "\n",
    "We tracked average training and validation loss for each epoch. We can plot these to verify that the loss reduced over the training process and to detect *over-fitting* (which is indicated by a continued drop in training loss after validation loss has levelled out or started to increase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "epoch_nums = range(1,num_epochs+1)\n",
    "training_loss = history.history[\"loss\"]\n",
    "validation_loss = history.history[\"val_loss\"]\n",
    "plt.plot(epoch_nums, training_loss)\n",
    "plt.plot(epoch_nums, validation_loss)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['training', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model performance\n",
    "\n",
    "We can see the final accuracy based on the test data, but typically we'll want to explore performance metrics in a little more depth. Let's plot a confusion matrix to see how well the model is predicting each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions from validation data...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tensorflow doesn't have a built-in confusion matrix metric, so we'll use SciKit-Learn\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Generating predictions from validation data...\")\n",
    "# Get the image and label arrays for the first batch of validation data\n",
    "x_test = validation_generator[0][0]\n",
    "y_test = validation_generator[0][1]\n",
    "\n",
    "# Use the model to predict the class\n",
    "class_probabilities = model.predict(x_test)\n",
    "\n",
    "# The model returns a probability value for each class\n",
    "# The one with the highest probability is the predicted class\n",
    "predictions = np.argmax(class_probabilities, axis=1)\n",
    "\n",
    "# The actual labels are hot encoded (e.g. [0 1 0], so get the one with the value 1\n",
    "true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classnames))\n",
    "plt.xticks(tick_marks, classnames, rotation=85)\n",
    "plt.yticks(tick_marks, classnames)\n",
    "plt.xlabel(\"Actual Shape\")\n",
    "plt.ylabel(\"Predicted Shape\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the trained model\n",
    "\n",
    "Now that we've trained the model, we can use it to predict the class of an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "square\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from random import randint\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def create_image (size, shape):\n",
    "    from random import randint\n",
    "    import numpy as np\n",
    "    from PIL import Image, ImageDraw\n",
    "    \n",
    "    xy1 = randint(10,40)\n",
    "    xy2 = randint(60,100)\n",
    "    col = (randint(0,200), randint(0,200), randint(0,200))\n",
    "\n",
    "    img = Image.new(\"RGB\", size, (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    if shape == 'circle':\n",
    "        draw.ellipse([(xy1,xy1), (xy2,xy2)], fill=col)\n",
    "    elif shape == 'triangle':\n",
    "        draw.polygon([(xy1,xy1), (xy2,xy2), (xy2,xy1)], fill=col)\n",
    "    else: # square\n",
    "        draw.rectangle([(xy1,xy1), (xy2,xy2)], fill=col)\n",
    "    del draw\n",
    "    \n",
    "    return np.array(img)\n",
    "\n",
    "# Create a random test image\n",
    "img = create_image ((224,224), classnames[randint(0, len(classnames)-1)])\n",
    "plt.imshow(img)\n",
    "\n",
    "# Modify the image data to match the format of the training features\n",
    "img = np.array(Image.fromarray(img))\n",
    "imgfeatures = img.reshape(1, img.shape[0], img.shape[1], img.shape[2])\n",
    "imgfeatures = imgfeatures.astype('float32')\n",
    "imgfeatures /= 255\n",
    "\n",
    "# Use the classifier to predict the class\n",
    "predicted_class = model.predict(imgfeatures)\n",
    "# Find the class with the highest predicted probability\n",
    "i = np.where(predicted_class == predicted_class.max())\n",
    "print (classnames[int(i[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn More\n",
    "\n",
    "* [Tensorflow Documentation](https://www.tensorflow.org/tutorials/images/transfer_learning)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
